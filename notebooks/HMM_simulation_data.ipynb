{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden markov model (HMM)\n",
    "\n",
    "The goal is to use to find looped and unlooped states in the data generated by Pavel's model.\n",
    "\n",
    "We will use Gaussian model for emission. \n",
    "Given all the data we fit the all the parameters (gaussian parameters, transition probability between looped/unlooped).\n",
    "\n",
    "Once we have the model, we use the model to predict the states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import glob\n",
    "import pathlib\n",
    "import gdown\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reproducible = True\n",
    "distance_conversion = (0.012*np.sqrt(40)) # 1 a.u. = 0.08 um\n",
    "rolling = 1\n",
    "if reproducible:\n",
    "    np.random.seed(42)\n",
    "subsample = False\n",
    "\n",
    "if subsample:\n",
    "    number_subsample = 200000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading simulated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extruder speed: <br>\n",
    "17500 -- 1 kb/s <br>\n",
    "175000 -- 0.1 kb/s <br>\n",
    "\n",
    "Loading rate: <br>\n",
    "arbitrary units multiply by 6 to convert to (1/Mb*min) <br>\n",
    "\n",
    "Unloading rate: <br>\n",
    "0.1 -- 5.5 min <br>\n",
    "0.01 -- 55 min <br>\n",
    "etc. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_name = \"langevin_release_on-off_220125\"\n",
    "basedir = f\"./{dataset_name}/\"\n",
    "#create a folder\n",
    "pathlib.Path(basedir).mkdir(parents=True, exist_ok=True)\n",
    "# polymer simulations, single loop dataset\n",
    "sample_link = \"https://drive.google.com/uc?export=download&id=1bubsOltpWp8HbkIi4kLcKP5q1HXa0JQ4\"\n",
    "# download data if not already present\n",
    "if not os.path.isfile(basedir+f\"{dataset_name}.zip\"):\n",
    "    gdown.download(sample_link, basedir+f\"{dataset_name}.zip\")\n",
    "\n",
    "#unzip the data\n",
    "with zipfile.ZipFile(basedir+f\"{dataset_name}.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(basedir)\n",
    "list_files = glob.glob(f\"{basedir}/*/*/*/*/*/dst_bnd.dat\")\n",
    "\n",
    "filenames = pd.DataFrame(list_files, columns=[\"filename\"])\n",
    "filenames[[\"ctcf\", \"speed\", \"loading\", \"unloading\", \"rep\"]] = filenames[\"filename\"].str.extract(\n",
    "    r\"langevin_release_on-off_220125\\/([\\w+]*)\\/([\\d+]*)\\/([\\d]\\.[\\d+]*)\\/([\\d]\\.[\\d+]*)\\/([\\d+]*)\\/\",\n",
    "    expand=True,\n",
    ")\n",
    "filenames[\"condition\"] = filenames[\"speed\"] + \".\" + filenames[\"loading\"] + \"_\" + filenames[\"unloading\"]\n",
    "filenames[\"uniqueid\"] = (\n",
    "    \"ctcf\"\n",
    "    + filenames[\"ctcf\"]\n",
    "    + \".\"\n",
    "    + \"rad21\"\n",
    "    + \"on\"\n",
    "    + \"_\"\n",
    "    + filenames[\"speed\"]\n",
    "    + \".\"\n",
    "    + filenames[\"loading\"]\n",
    "    + \".\"\n",
    "    + filenames[\"unloading\"]\n",
    "    + \".\"\n",
    "    + filenames[\"rep\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf = []\n",
    "for condition, sub2 in filenames.groupby('condition'):\n",
    "    for uniqueid, sub1 in sub2.groupby('uniqueid'):\n",
    "        for ct, sub in sub1.groupby('ctcf'):\n",
    "            for file in sub.filename.unique():\n",
    "                tmp = pd.read_csv(file, sep=\" \")\n",
    "                tmp.distance = tmp.distance * distance_conversion\n",
    "                try:\n",
    "                    tmp.drop([\"x1\", \"y1\", \"z1\", \"x2\", \"y2\", \"z2\"], axis =1, inplace=True)\n",
    "                except:\n",
    "                    pass\n",
    "                tmp['condition'] = condition\n",
    "                tmp['frame'] = np.arange(len(tmp))\n",
    "                tmp['uniqueid'] = uniqueid \n",
    "                tmp['ctcf'] = ct\n",
    "                tmp['rad21'] = \"on\"\n",
    "                if subsample:\n",
    "                    tmp = tmp.head(number_subsample)\n",
    "                alldf.append(tmp)\n",
    "distances_original = pd.concat(alldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsampling  to 30s and training 2 state hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose neighbors\n",
    "nneighbor = 2\n",
    "subsample_every = 1\n",
    "\n",
    "distances = distances_original.iloc[::subsample_every].copy()\n",
    "distances.bond = 1 - distances.bond.values\n",
    "distances_nonoise = distances.copy()\n",
    "# add experimental noise\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "distances.distance = distances.distance.values + np.random.normal(\n",
    "    loc=0.0, scale=0.064, size=len(distances)\n",
    ")\n",
    "distances.frame = distances.frame.values / subsample_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run HMM training on all conditions\n",
    "results = {}\n",
    "np.random.seed(seed)\n",
    "for condition, sub in distances.groupby(\"condition\"):\n",
    "    traj2d = np.reshape(\n",
    "        sub[sub.ctcf == \"on\"].distance.to_numpy(),\n",
    "        (-1, 1),\n",
    "    )\n",
    "    model = hmm.GaussianHMM(\n",
    "        n_components=2,\n",
    "        covariance_type=\"full\",\n",
    "        min_covar=0.1,\n",
    "        n_iter=10000,\n",
    "        params=\"mtc\",\n",
    "        init_params=\"mtc\",\n",
    "    )\n",
    "    model.startprob_ = [0.5, 0.5]\n",
    "    model.fit(traj2d)\n",
    "\n",
    "    results[condition] = model\n",
    "models2hmm = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder HMM model such that the first gaussian is always the lowest\n",
    "for key, model in results.items():\n",
    "    newmodel = reorder_hmm_model_parameters(model)\n",
    "    model = newmodel\n",
    "    means = (model.means_)\n",
    "    sigmas = np.sqrt(model.covars_.squeeze())\n",
    "    w = np.array(model.transmat_)\n",
    "    logProb = model.score(traj2d)\n",
    "    print(f\"ctcf-speed-loading-unloading = {key}\")\n",
    "    print(f\"Gaussian means: {means}\")\n",
    "    print(f\"Gaussian std: {sigmas}\")\n",
    "    print(f\"Transition rates: {w}\")\n",
    "    print(\"----------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments\n",
    "\n",
    "dataset = \"211221_two_colors_distance_30s.csv\"\n",
    "basedir = f\"./{dataset}/\"\n",
    "#create a folder\n",
    "pathlib.Path(basedir).mkdir(parents=True, exist_ok=True)\n",
    "sample_link = \"https://drive.google.com/uc?export=download&id=1szF0P4OcA0X8WoPha5CKjo0sCLhJnrtX\"\n",
    "if not os.path.isfile(f\"{basedir}{dataset}.zip\"):\n",
    "    gdown.download(sample_link, f\"{basedir}{dataset}.zip\")\n",
    "#unzip the data\n",
    "with zipfile.ZipFile(f\"{basedir}{dataset}.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(basedir)\n",
    "    \n",
    "list_cell_lines = [\"1A2\", \"1B1\"]\n",
    "bins = np.arange(30, 10000, 150)\n",
    "\n",
    "#download pretrained hmm model\n",
    "gdown.download(\n",
    "    \"https://drive.google.com/uc?export=download&id=1oGTB_Ml4RQpwCeHackjYd2Tc_MDd6sqm\", \n",
    "    f\"{basedir}hmmmodel_two_colors_distance_30s.obj\",\n",
    ")\n",
    "with open(f\"{basedir}/hmmmodel_two_colors_distance_30s.obj\", \"rb\") as f:\n",
    "    exp_model = pickle.load(f)\n",
    "\n",
    "exp = pd.read_csv(f\"{basedir}{dataset}\")\n",
    "exp = exp[exp.cell_line.isin(list_cell_lines)]\n",
    "exp[\"condition\"] = exp[\"cell_line\"] + \"_\" + exp[\"induction_time\"]\n",
    "\n",
    "hue_order = sorted(exp[\"condition\"].unique())\n",
    "(\n",
    "    exp_durations,\n",
    "    exp_second_passage_times,\n",
    "    exp_frequencies,\n",
    "    exp_fraction_time,\n",
    "    exp_conditions,\n",
    "    exp_data_filtered,\n",
    ") = calculate_duration_second_passage_time(\n",
    "    data=exp,\n",
    "    resolution=30,\n",
    "    model=exp_model,\n",
    "    fraction_nan_max=0.2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appo = pd.DataFrame(1- exp_data_filtered.groupby(\"condition\").prediction.mean())\n",
    "ft_noCTCF_yescohesin = appo.prediction[appo.index == \"1A2_0min\"].values[0]\n",
    "ft_noCTCF_nocohesin = appo.prediction[appo.index == \"1A2_120min\"].values[0]\n",
    "ft_yesCTCF_yescohesin = appo.prediction[appo.index == \"1B1_0min\"].values[0]\n",
    "ft_yesCTCF_nocohesin = appo.prediction[appo.index == \"1B1_120min\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appo = pd.DataFrame(exp_durations.groupby(\"condition\").contact_duration.mean())\n",
    "duration_noCTCF_yescohesin = appo.contact_duration[appo.index == \"1A2_0min\"].values[0]\n",
    "duration_noCTCF_nocohesin = appo.contact_duration[appo.index == \"1A2_120min\"].values[0]\n",
    "duration_yesCTCF_yescohesin = appo.contact_duration[appo.index == \"1B1_0min\"].values[0]\n",
    "duration_yesCTCF_nocohesin = appo.contact_duration[appo.index == \"1B1_120min\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appo = pd.DataFrame(exp_second_passage_times.groupby(\"condition\").second_passage_time.mean())\n",
    "spt_noCTCF_yescohesin = appo.second_passage_time[appo.index == \"1A2_0min\"].values[0]\n",
    "spt_noCTCF_nocohesin = appo.second_passage_time[appo.index == \"1A2_120min\"].values[0]\n",
    "spt_yesCTCF_yescohesin = appo.second_passage_time[appo.index == \"1B1_0min\"].values[0]\n",
    "spt_yesCTCF_nocohesin = appo.second_passage_time[appo.index == \"1B1_120min\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best case to reproduce experimental data in +cohesin condition +/- CTCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the mean contact duration and second passage time across all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lst = []# = pd.DataFrame()\n",
    "alldata_lst = []# = pd.DataFrame()\n",
    "sim_duration_distributions = pd.DataFrame()\n",
    "for cond, distances_selected in distances.groupby(\"condition\"):\n",
    "    distances_selected.condition = distances_selected.uniqueid.map(lambda x: str(x)[:-2])\n",
    "    (\n",
    "        durations,\n",
    "        second_passage_times,\n",
    "        frequencies,\n",
    "        fraction_time,\n",
    "        conditions,\n",
    "        data,\n",
    "    ) = calculate_duration_second_passage_time(\n",
    "        distances_selected, resolution=30, model=results[cond]\n",
    "    )\n",
    "    tmp = pd.DataFrame(\n",
    "        durations.groupby(\"cell_line\").mean()[\"contact_duration\"]\n",
    "    ).reset_index()\n",
    "    tmp[\"second_passage_time\"] = (\n",
    "        second_passage_times.groupby(\"cell_line\").mean()[\"second_passage_time\"].values\n",
    "    )\n",
    "    tmp[\"frequency\"] = 1/(frequencies.groupby(\"cell_line\").mean()[\"frequency\"].values) * 1000\n",
    "    tmp[\"condition\"] = cond\n",
    "    mean_lst.append(tmp)\n",
    "    alldata_lst.append(data)\n",
    "mean = pd.concat(mean_lst)\n",
    "alldata = pd.concat(alldata_lst)\n",
    "\n",
    "mean[[\"speed\", \"loading\", \"unloading\"]] = mean[\"condition\"].str.extract(\n",
    "    r\"([\\d+]*)\\.([\\d]\\.[\\d+]*)_([\\d]\\.[\\d+]*)\", expand=True\n",
    ")\n",
    "mean[\"ctcf\"] = mean[\"cell_line\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting gaussian means of HMM model from simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_means = pd.DataFrame()\n",
    "\n",
    "for key, model in results.items():\n",
    "    tmp = pd.DataFrame(model.means_, columns=[\"gaussian_means\"])\n",
    "    tmp[\"state\"] = [\"looped\", \"unlooped\"]\n",
    "    tmp[\"condition\"] = key\n",
    "    gaussian_means = pd.concat([gaussian_means, tmp])\n",
    "gaussian_means[[\"speed\", \"loading\", \"unloading\"]] = gaussian_means[\n",
    "    \"condition\"\n",
    "].str.extract(r\"([\\d+]*)\\.([\\d]\\.[\\d+]*)_([\\d]\\.[\\d+]*)\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate distance of gaussian means between simulation and experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_gaussian_means_looped = gaussian_means[[\"gaussian_means\", \"condition\"]][gaussian_means.state == \"looped\"]\n",
    "dist_gaussian_means_unlooped = gaussian_means[[\"gaussian_means\", \"condition\"]][gaussian_means.state == \"unlooped\"]\n",
    "dist_gaussian_means_looped[\"gaussian_means\"] = np.abs(dist_gaussian_means_looped[\"gaussian_means\"].values - 0.1493922) / 0.1493922\n",
    "dist_gaussian_means_unlooped[\"gaussian_means\"] = np.abs(dist_gaussian_means_unlooped[\"gaussian_means\"].values - 0.28807371) / 0.28807371\n",
    "\n",
    "dist_gaussian_means = pd.merge(dist_gaussian_means_looped, dist_gaussian_means_unlooped, on=\"condition\")\n",
    "# since we want to keep only the looped state\n",
    "dist_gaussian_means[\"dist_gaussian_means\"] = dist_gaussian_means.gaussian_means_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Gaussian mean as heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf = PdfPages(f\"{dataset_name}_2states_HMM_neighbor_{nneighbor}.pdf\")\n",
    "\n",
    "speed = \"17500\"\n",
    "exp_looped = 0.1493922\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [(1, 1, 1),(69/255, 83/255, 162/255),(1, 1, 1)])\n",
    "norm = mcolors.TwoSlopeNorm(vmin=exp_looped*0.5, vcenter=exp_looped, vmax=exp_looped*1.5)\n",
    "fig, ax = plt.subplots(1,2, figsize = (12, 5))\n",
    "sns.heatmap(\n",
    "    gaussian_means[(gaussian_means.state==\"looped\") & (gaussian_means.speed == speed)].pivot(\"loading\", \"unloading\", \"gaussian_means\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"gaussian_means looped\"},\n",
    "    norm = norm, \n",
    "    ax = ax[0]\n",
    ")\n",
    "ax[0].set_title(f\"exp value looped {exp_looped}\")\n",
    "\n",
    "exp_unlooped = 0.28807371\n",
    "norm = mcolors.TwoSlopeNorm(vmin=exp_unlooped*0.5, vcenter=exp_unlooped, vmax=exp_unlooped*1.5)\n",
    "sns.heatmap(\n",
    "    gaussian_means[(gaussian_means.state==\"unlooped\") & (gaussian_means.speed == speed)].pivot(\"loading\", \"unloading\", \"gaussian_means\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"gaussian_means looped\"},\n",
    "    norm = norm, \n",
    "    ax = ax[1]\n",
    ")\n",
    "ax[1].set_title(f\"exp value unlooped {exp_unlooped}\")\n",
    "plt.suptitle(f\"Gaussian means speed: {speed}\")\n",
    "plt.show()\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot average first passage time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = \"17500\"\n",
    "ctcf_off = spt_noCTCF_yescohesin\n",
    "norm = mcolors.TwoSlopeNorm(vmin=ctcf_off*0, vcenter=ctcf_off, vmax=ctcf_off*2)\n",
    "fig, ax = plt.subplots(1,2, figsize = (20, 8))\n",
    "sns.heatmap(\n",
    "    mean[(mean.ctcf==\"ctcfoff.rad21on\") & (mean.speed == speed)].pivot(\"loading\", \"unloading\", \"second_passage_time\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"CTCF off\"},\n",
    "    norm = norm, \n",
    "    annot_kws={\"size\":8},\n",
    "    ax = ax[0]\n",
    ")\n",
    "ax[0].set_title(f\"exp value {ctcf_off}\")\n",
    "\n",
    "ctcf_on = spt_yesCTCF_yescohesin\n",
    "norm = mcolors.TwoSlopeNorm(vmin=ctcf_on*0, vcenter=ctcf_on, vmax=ctcf_on*2)\n",
    "sns.heatmap(\n",
    "    mean[(mean.ctcf==\"ctcfon.rad21on\") & (mean.speed == speed)].pivot(\"loading\", \"unloading\", \"second_passage_time\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"CTCF on\"},\n",
    "    norm = norm, \n",
    "    annot_kws={\"size\":8},\n",
    "    ax = ax[1]\n",
    ")\n",
    "ax[1].set_title(f\"exp value {ctcf_on}\")\n",
    "plt.suptitle(\"Second_passage_time\")\n",
    "plt.show()\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot average contact duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = \"17500\"\n",
    "ctcf_off = duration_noCTCF_yescohesin\n",
    "norm = mcolors.TwoSlopeNorm(vmin=ctcf_off*0, vcenter=ctcf_off, vmax=ctcf_off*2)\n",
    "fig, ax = plt.subplots(1,2, figsize = (20, 8))\n",
    "sns.heatmap(\n",
    "    mean[(mean.ctcf==\"ctcfoff.rad21on\") & (mean.speed == speed)].pivot(\"loading\", \"unloading\", \"contact_duration\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"CTCF off\"},\n",
    "    norm = norm, \n",
    "    annot_kws={\"size\":8},\n",
    "    ax = ax[0]\n",
    ")\n",
    "ax[0].set_title(f\"exp value {ctcf_off}\")\n",
    "\n",
    "ctcf_on = duration_yesCTCF_yescohesin\n",
    "norm = mcolors.TwoSlopeNorm(vmin=ctcf_on*0, vcenter=ctcf_on, vmax=ctcf_on*2)\n",
    "sns.heatmap(\n",
    "    mean[(mean.ctcf==\"ctcfon.rad21on\") & (mean.speed == speed)].pivot(\"loading\", \"unloading\", \"contact_duration\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"CTCF on\"},\n",
    "    norm = norm, \n",
    "    annot_kws={\"size\":8},\n",
    "    ax = ax[1]\n",
    ")\n",
    "ax[1].set_title(f\"exp value {ctcf_on}\")\n",
    "plt.suptitle(\"Contact duration\")\n",
    "plt.show()\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate distance between contact duration between simulation and experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_contact_duration = []\n",
    "conditions = []\n",
    "\n",
    "for cond, sub in mean.groupby(\"condition\"):\n",
    "    conditions.append(cond)\n",
    "    appo = np.abs(sub.contact_duration[sub.cell_line == \"ctcfoff.rad21on\"].values - ctcf_off)/ctcf_off\n",
    "    appo = appo + np.abs(sub.contact_duration[sub.cell_line == \"ctcfon.rad21on\"].values - ctcf_on)/ctcf_on\n",
    "    dist_contact_duration.append(appo)\n",
    "\n",
    "dist_contact_duration = pd.DataFrame(dist_contact_duration, columns = [\"dist_contact_duration\"])\n",
    "dist_contact_duration[\"condition\"] = conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM fraction of time spend in each looped across all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = np.unique(\n",
    "    [\n",
    "        x.replace(\"ctcfon.\", \"\").replace(\"ctcfoff.\", \"\")\n",
    "        for x in alldata.condition.unique()\n",
    "    ]\n",
    ")\n",
    "\n",
    "lst_time_spent = []\n",
    "for cond in conditions:\n",
    "    subset_on = alldata[\n",
    "        [\"ctcfon.\" + cond in x for x in alldata.condition]\n",
    "    ].copy()\n",
    "    subset_off = alldata[\n",
    "        [\"ctcfoff.\" + cond in x for x in alldata.condition]\n",
    "    ].copy()\n",
    "    \n",
    "    time = pd.DataFrame(\n",
    "    [\n",
    "        1 - subset_on.prediction.mean(),\n",
    "        1 - subset_off.prediction.mean(),\n",
    "    ],\n",
    "    columns=[\"time\"],\n",
    "    )\n",
    "\n",
    "    time[\"ctcf\"] = [\"on\", \"off\"]\n",
    "    time[\"type\"] = cond\n",
    "    lst_time_spent.append(time)\n",
    "time_spent = pd.concat(lst_time_spent)\n",
    "\n",
    "time_spent[[\"speed\", \"loading\", \"unloading\"]] = time_spent[\"type\"].str.extract(\n",
    "    r\"([\\d+]*)\\.([\\d]\\.[\\d+]*)\\.([\\d]\\.[\\d+]*)\", expand=True\n",
    ")\n",
    "\n",
    "speed = \"17500\"\n",
    "ctcf_off = ft_noCTCF_yescohesin\n",
    "norm = mcolors.TwoSlopeNorm(vmin=ctcf_off*0.5, vcenter=ctcf_off, vmax=ctcf_off*1.3)\n",
    "fig, ax = plt.subplots(1,2, figsize = (12, 5))\n",
    "sns.heatmap(\n",
    "    time_spent[(time_spent.ctcf==\"off\") & (time_spent.speed == speed)].pivot(\"loading\", \"unloading\", \"time\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"CTCF off\"},\n",
    "    norm = norm, \n",
    "    annot_kws={\"size\":8},\n",
    "    ax = ax[0]\n",
    ")\n",
    "ax[0].set_title(f\"exp value {ctcf_off}\")\n",
    "\n",
    "ctcf_on = ft_yesCTCF_yescohesin\n",
    "norm = mcolors.TwoSlopeNorm(vmin=ctcf_on*0.5, vcenter=ctcf_on, vmax=ctcf_on*1.3)\n",
    "sns.heatmap(\n",
    "    time_spent[(time_spent.ctcf==\"on\") & (time_spent.speed == speed)].pivot(\"loading\", \"unloading\", \"time\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"CTCF on\"},\n",
    "    norm = norm, \n",
    "    annot_kws={\"size\":8},\n",
    "    ax = ax[1]\n",
    ")\n",
    "ax[1].set_title(f\"exp value {ctcf_on}\")\n",
    "plt.suptitle(f\"Fraction time spent in looped state; speed {speed}\")\n",
    "plt.show()\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### effect of CTCF in time spent in the looped state across all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctcfon = time_spent[(time_spent.ctcf==\"on\") ].copy()\n",
    "ctcfoff = time_spent[(time_spent.ctcf==\"off\") ].copy()\n",
    "\n",
    "ctcf = pd.merge(ctcfon, ctcfoff, on = [\"loading\", \"unloading\", \"speed\"])\n",
    "ctcf[\"enrichment\"] = ctcf[\"time_x\"] / ctcf[\"time_y\"]\n",
    "ctcf[\"difference\"] =  ctcf[\"time_x\"] - ctcf[\"time_y\"]\n",
    "\n",
    "speed=\"17500\"\n",
    "\n",
    "enrichment =  ft_yesCTCF_yescohesin/ ft_noCTCF_yescohesin\n",
    "norm = mcolors.TwoSlopeNorm(vmin=enrichment*0.5, vcenter=enrichment, vmax=enrichment*2)\n",
    "fig, ax = plt.subplots(1,2, figsize = (12, 5))\n",
    "sns.heatmap(\n",
    "    ctcf[ctcf.speed == speed].pivot(\"loading\", \"unloading\", \"enrichment\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"Fold change (+ vs - ctcf)\"},\n",
    "    norm = norm, \n",
    "    annot_kws={\"size\":8},\n",
    "    ax = ax[0]\n",
    "   \n",
    ")\n",
    "\n",
    "ax[0].set_title(f\"Exp value {enrichment}\")\n",
    "\n",
    "difference = ft_yesCTCF_yescohesin- ft_noCTCF_yescohesin\n",
    "norm = mcolors.TwoSlopeNorm(vmin=difference*0.5, vcenter=difference, vmax=difference*2)\n",
    "sns.heatmap(\n",
    "    ctcf[ctcf.speed == speed].pivot(\"loading\", \"unloading\", \"difference\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"Difference (+ vs - ctcf)\"},\n",
    "    norm = norm, \n",
    "    annot_kws={\"size\":8},\n",
    "    ax = ax[1]\n",
    "   \n",
    ")\n",
    "\n",
    "ax[1].set_title(f\"Exp value {difference}\")\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle(f\"Change in  time spent in looped state (+ vs -ctcf); exp value {enrichment}; speed {speed}\")\n",
    "plt.show()\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist_ctcf_enrichment = ctcf.copy()\n",
    "dist_ctcf_enrichment[\"dist_ctcf_enrichment\"] = np.abs(\n",
    "    dist_ctcf_enrichment.time_x - ft_yesCTCF_yescohesin\n",
    ") /ft_yesCTCF_yescohesin  + np.abs(dist_ctcf_enrichment.time_y - ft_yesCTCF_nocohesin) / ft_yesCTCF_nocohesin\n",
    "\n",
    "dist_gaussian_means[\n",
    "    \"newcondition\"\n",
    "] = \"rad21on_\" + dist_gaussian_means.condition.str.replace(\"_\", \".\")\n",
    "dist_contact_duration[\n",
    "    \"newcondition\"\n",
    "] = \"rad21on_\" + dist_contact_duration.condition.str.replace(\"_\", \".\")\n",
    "\n",
    "dist_together = pd.merge(\n",
    "    dist_gaussian_means, dist_ctcf_enrichment, left_on=\"newcondition\", right_on=\"type_x\"\n",
    ")\n",
    "dist_together = pd.merge(dist_together, dist_contact_duration, on=\"newcondition\")\n",
    "dist_together[\"dist\"] = (\n",
    "    2*dist_together.dist_gaussian_means\n",
    "    + dist_together.dist_ctcf_enrichment\n",
    "    + dist_together.dist_contact_duration\n",
    ")\n",
    "\n",
    "dist_together[[\"speed\", \"loading\", \"unloading\"]] = dist_together[\n",
    "    \"condition_x\"\n",
    "].str.extract(r\"([\\d+]*)\\.([\\d]\\.[\\d+]*)_([\\d]\\.[\\d+]*)\", expand=True)\n",
    "\n",
    "minimum = dist_together.dist.min()\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (12, 5))\n",
    "speed = \"17500\"\n",
    "cmap = \"Greens_r\"\n",
    "\n",
    "sns.heatmap(\n",
    "    dist_together[dist_together.speed == speed].pivot(\"loading\", \"unloading\", \"dist\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"Deviation from experimental data\"},\n",
    "    vmin=0,\n",
    "    vmax=8,\n",
    "    annot_kws={\"size\": 8},\n",
    "    ax = ax[0]\n",
    ")\n",
    "ax[0].set_title(f\"speed {speed}\")\n",
    "\n",
    "speed = \"175000\"\n",
    "sns.heatmap(\n",
    "    dist_together[dist_together.speed == speed].pivot(\"loading\", \"unloading\", \"dist\"),\n",
    "    annot=True,\n",
    "    cmap=cmap,\n",
    "    cbar_kws={\"label\": \"Deviation from experimental data\"},\n",
    "    vmin=0,\n",
    "    vmax=8,\n",
    "    annot_kws={\"size\": 8},\n",
    "    ax = ax[1]\n",
    ")\n",
    "ax[1].set_title(f\"speed {speed}\")\n",
    "\n",
    "plt.suptitle(\"Best combination to match experimental data\")\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 5 #number of best matches\n",
    "dist_together[\"realistic\"] = (\n",
    "    dist_together[\"speed\"]\n",
    "    + \".\"\n",
    "    + dist_together[\"loading\"]\n",
    "    + \".\"\n",
    "    + dist_together[\"unloading\"]\n",
    ")\n",
    "\n",
    "realistic_list = dist_together.sort_values('dist').head(top).realistic.values\n",
    "realistic_model_list = dist_together.sort_values('dist').head(top).condition_x.values\n",
    "\n",
    "realistic_best = realistic_list[0]\n",
    "realistic_model_best = realistic_model_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select best -cohesin case\n",
    "This case should contain small amount of cohesin similar to experimental system but the unloading properties shouldn't be affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nocohesin = '17500.0.002_0.01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select best datasets\n",
    "\n",
    "### This part can be removed when we have a consistent dataset formats\n",
    "\n",
    "Just keep this part and move it to the top reading file part\n",
    "\n",
    "                try:\n",
    "                    tmp.drop([\"x1\", \"y1\", \"z1\", \"x2\", \"y2\", \"z2\"], axis =1, inplace=True)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"langevin_release_on-off_220125\"\n",
    "basedir = f\"./{dataset_name}/\"\n",
    "#create a folder\n",
    "pathlib.Path(basedir).mkdir(parents=True, exist_ok=True)\n",
    "# polymer simulations, single loop dataset\n",
    "sample_link = \"https://drive.google.com/uc?export=download&id=1bubsOltpWp8HbkIi4kLcKP5q1HXa0JQ4\"\n",
    "# download data if not already present\n",
    "if not os.path.isfile(basedir+f\"{dataset_name}.zip\"):\n",
    "    gdown.download(sample_link, basedir+f\"{dataset_name}.zip\")\n",
    "#unzip the data\n",
    "with zipfile.ZipFile(basedir+f\"{dataset_name}.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(basedir)\n",
    "list_files = glob.glob(f\"{basedir}/*/*/*/*/*/dst_bnd.dat\")\n",
    "\n",
    "filenames = pd.DataFrame(list_files, columns=[\"filename\"])\n",
    "filenames[[\"ctcf\", \"speed\", \"loading\", \"unloading\", \"rep\"]] = filenames[\"filename\"].str.extract(\n",
    "    fr\"{dataset_name}\\/([\\w+]*)\\/([\\d+]*)\\/([\\d]\\.[\\d+]*)\\/([\\d]\\.[\\d+]*)\\/([\\d+]*)\\/\",\n",
    "    expand=True,\n",
    ")\n",
    "filenames[\"condition\"] = filenames[\"speed\"] + \".\" + filenames[\"loading\"] + \"_\" + filenames[\"unloading\"]\n",
    "filenames[\"uniqueid\"] = (\n",
    "    \"ctcf\"\n",
    "    + filenames[\"ctcf\"]\n",
    "    + \".\"\n",
    "    + \"rad21\"\n",
    "    + \"on\"\n",
    "    + \"_\"\n",
    "    + filenames[\"speed\"]\n",
    "    + \".\"\n",
    "    + filenames[\"loading\"]\n",
    "    + \".\"\n",
    "    + filenames[\"unloading\"]\n",
    "    + \".\"\n",
    "    + filenames[\"rep\"]\n",
    ")\n",
    "\n",
    "\n",
    "best_filenames = filenames[filenames.condition.isin(np.append(realistic_model_list, best_nocohesin))]\n",
    "alldf = []\n",
    "for condition, sub2 in best_filenames.groupby('condition'):\n",
    "    print(condition)\n",
    "    for uniqueid, sub1 in sub2.groupby('uniqueid'):\n",
    "        for ct, sub in sub1.groupby('ctcf'):\n",
    "            for file in sub.filename.unique():\n",
    "                tmp = pd.read_csv(file, sep=\" \")\n",
    "                try:\n",
    "                    tmp.drop([\"x1\", \"y1\", \"z1\", \"x2\", \"y2\", \"z2\"], axis =1, inplace=True)\n",
    "                except:\n",
    "                    pass\n",
    "                tmp.distance = tmp.distance * distance_conversion\n",
    "                tmp['condition'] = condition\n",
    "                tmp['frame'] = np.arange(len(tmp))\n",
    "                tmp['uniqueid'] = uniqueid \n",
    "                tmp['ctcf'] = ct\n",
    "                tmp['rad21'] = \"on\"\n",
    "                if subsample:\n",
    "                    tmp = tmp.head(number_subsample)\n",
    "                alldf.append(tmp)\n",
    "distances_best_original = pd.concat(alldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose neighbors\n",
    "nneighbor = 2\n",
    "subsample_every = 1\n",
    "\n",
    "#idx = np.where(\n",
    "#    np.array([abs(eval(x)) for x in distances_best_original.columns[1:][:-5]])\n",
    "#    < 18 - nneighbor\n",
    "#)[0]\n",
    "#names_remove = distances_best_original.columns[idx + 1]\n",
    "#\n",
    "## subsampling and remove too far neighbors \n",
    "distances = distances_best_original.iloc[::subsample_every].copy()\n",
    "#\n",
    "## calculate the GT ctcf mediated loop\n",
    "#idx = (\n",
    "#    np.where(\n",
    "#        np.array([abs(eval(x)) for x in distances.columns[1:][:-5]]) >= 18 - nneighbor\n",
    "#    )[0]\n",
    "#    + 1\n",
    "#)\n",
    "#distances[\"bond\"] = distances.iloc[:, idx].sum(axis=1)\n",
    "#distances.loc[distances.bond > 1, \"bond\"] = 1\n",
    "#distances.bond = 1 - distances.bond.values\n",
    "\n",
    "distances_nonoise = distances.copy()\n",
    "\n",
    "# add experimental noise\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "distances.distance = distances.distance.values + np.random.normal(\n",
    "    loc=0.0, scale=0.064, size=len(distances)\n",
    ")\n",
    "distances.frame = distances.frame.values / subsample_every"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fraction of time spent in each state in the best case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distances_control = distances[distances.condition == best_nocohesin]\n",
    "\n",
    "traj = distances_control.distance.values.reshape(-1, 1)\n",
    "time_average = pd.DataFrame()\n",
    "for realistic_select, realistic_model_select in zip(\n",
    "    realistic_list, realistic_model_list\n",
    "):\n",
    "    m = results[realistic_model_select]\n",
    "    distances_control = distances_control.assign(prediction = m.predict(traj))\n",
    "\n",
    "    subset_on = alldata[\n",
    "        [\"ctcfon.rad21on_\" + realistic_select in x for x in alldata.condition]\n",
    "    ].copy()\n",
    "    subset_off = alldata[\n",
    "        [\"ctcfoff.rad21on_\" + realistic_select in x for x in alldata.condition]\n",
    "    ].copy()\n",
    "\n",
    "    time = pd.DataFrame(\n",
    "        [\n",
    "            1 - subset_on.prediction.mean(),\n",
    "            1 - subset_on.bond.mean(),\n",
    "            1 - subset_off.prediction.mean(),\n",
    "            1 - subset_off.bond.mean(),\n",
    "            1 - distances_control[distances_control.ctcf == \"on\"].prediction.mean(),\n",
    "            1 - distances_control[distances_control.ctcf == \"on\"].bond.mean(),\n",
    "            1 - distances_control[distances_control.ctcf == \"off\"].prediction.mean(),\n",
    "            1 - distances_control[distances_control.ctcf == \"off\"].bond.mean(),\n",
    "            subset_on.prediction.mean(),\n",
    "            subset_on.bond.mean(),\n",
    "            subset_off.prediction.mean(),\n",
    "            subset_off.bond.mean(),\n",
    "            distances_control[distances_control.ctcf == \"on\"].prediction.mean(),\n",
    "            distances_control[distances_control.ctcf == \"on\"].bond.mean(),\n",
    "            distances_control[distances_control.ctcf == \"off\"].prediction.mean(),\n",
    "            distances_control[distances_control.ctcf == \"off\"].bond.mean(),\n",
    "        ],\n",
    "        columns=[\"time\"],\n",
    "    )\n",
    "\n",
    "    time[\"ctcf\"] = [\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "    ]\n",
    "    time[\"type\"] = [\n",
    "        \"pred\",\n",
    "        \"gt\",\n",
    "        \"pred\",\n",
    "        \"gt\",\n",
    "        \"pred\",\n",
    "        \"gt\",\n",
    "        \"pred\",\n",
    "        \"gt\",\n",
    "        \"pred\",\n",
    "        \"gt\",\n",
    "        \"pred\",\n",
    "        \"gt\",\n",
    "        \"pred\",\n",
    "        \"gt\",\n",
    "        \"pred\",\n",
    "        \"gt\",\n",
    "    ]\n",
    "    time[\"cohesin\"] = [\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"on\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "        \"off\",\n",
    "    ]\n",
    "    time[\"condition\"] = (\n",
    "        \"cohesin\" + time[\"cohesin\"] + \"_ctcf\" + time[\"ctcf\"] + \"_\" + time[\"type\"]\n",
    "    )\n",
    "    time[\"states\"] = [\n",
    "        \"looped\",\n",
    "        \"looped\",\n",
    "        \"looped\",\n",
    "        \"looped\",\n",
    "        \"looped\",\n",
    "        \"looped\",\n",
    "        \"looped\",\n",
    "        \"looped\",\n",
    "        \"unlooped\",\n",
    "        \"unlooped\",\n",
    "        \"unlooped\",\n",
    "        \"unlooped\",\n",
    "        \"unlooped\",\n",
    "        \"unlooped\",\n",
    "        \"unlooped\",\n",
    "        \"unlooped\",\n",
    "    ]\n",
    "    time[\"index\"] = np.arange(0, len(time))\n",
    "    \n",
    "    # plot bootstrap ci for best case\n",
    "    if realistic_select == realistic_best:\n",
    "        ddsets = [\n",
    "            1 - subset_on.prediction,\n",
    "            1 - subset_on.bond,\n",
    "            1 - subset_off.prediction,\n",
    "            1 - subset_off.bond,\n",
    "            1 - distances_control[distances_control.ctcf == \"on\"].prediction,\n",
    "            1 - distances_control[distances_control.ctcf == \"on\"].bond,\n",
    "            1 - distances_control[distances_control.ctcf == \"off\"].prediction,\n",
    "            1 - distances_control[distances_control.ctcf == \"off\"].bond,\n",
    "            subset_on.prediction,\n",
    "            subset_on.bond,\n",
    "            subset_off.prediction,\n",
    "            subset_off.bond,\n",
    "            distances_control[distances_control.ctcf == \"on\"].prediction,\n",
    "            distances_control[distances_control.ctcf == \"on\"].bond,\n",
    "            distances_control[distances_control.ctcf == \"off\"].prediction,\n",
    "            distances_control[distances_control.ctcf == \"off\"].bond,\n",
    "        ]\n",
    "        stds = []\n",
    "        for dataset in ddsets:\n",
    "            tmp = []\n",
    "            for i in range(10000):\n",
    "                tmp.append(\n",
    "                    dataset.iloc[\n",
    "                        np.random.choice(\n",
    "                            range(len(dataset)), size=int(len(dataset)*0.05), replace=True\n",
    "                        )\n",
    "                    ].mean()\n",
    "                )\n",
    "            stds.append(np.std(tmp))\n",
    "        time[\"std\"] = stds\n",
    "        \n",
    "        means = time.pivot(index=\"states\", columns=\"condition\", values=\"time\").T\n",
    "        errors = time.pivot(index=\"states\", columns=\"condition\", values=\"std\").T\n",
    "        print(means, errors)\n",
    "        fig = means.plot(kind=\"bar\", yerr=errors, stacked=True)\n",
    "        plt.ylabel(\"Fraction of time spent in looped state\")\n",
    "        plt.title(f\"Best case {realistic_best}\")\n",
    "        pdf.savefig(fig.figure, bbox_inches=\"tight\")\n",
    "        time.drop(\"std\", axis=1, inplace=True)\n",
    "    time_average = pd.concat([time, time_average])\n",
    "\n",
    "std = time_average.groupby(list(time_average.columns[1:])).std().reset_index()\n",
    "av = time_average.groupby(list(time_average.columns[1:])).mean().reset_index()\n",
    "av_std = pd.merge(std, av, on=list(time_average.columns[1:]))\n",
    "av_std.columns = [\n",
    "    \"ctcf\",\n",
    "    \"type\",\n",
    "    \"cohesin\",\n",
    "    \"condition\",\n",
    "    \"states\",\n",
    "    \"index\",\n",
    "    \"std\",\n",
    "    \"mean\",\n",
    "]\n",
    "\n",
    "means = av_std.pivot(index=\"states\", columns=\"condition\", values=\"mean\").T\n",
    "errors = av_std.pivot(index=\"states\", columns=\"condition\", values=\"std\").T\n",
    "fig = means.plot(kind=\"bar\", yerr=errors, stacked=True)\n",
    "\n",
    "plt.ylabel(\"Fraction of time spent in looped state\")\n",
    "plt.title(f\"average from {realistic_list}\")\n",
    "pdf.savefig(fig.figure, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_conditions = durations.condition.unique()\n",
    "for i in range(len(list_conditions)):\n",
    "    for j in range(i + 1, len(list_conditions)):\n",
    "        test = scipy.stats.ttest_ind(\n",
    "            durations.contact_duration[durations.condition == list_conditions[i]].values,\n",
    "            durations.contact_duration[durations.condition == list_conditions[j]].values,\n",
    "        )\n",
    "        print(f\"{list_conditions[i]} vs {list_conditions[j]} p-value pfrom two sided t.test {test.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fraction of time in looped state in exp and best case of simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_average = pd.DataFrame()\n",
    "for realistic_select in realistic_list:\n",
    "\n",
    "    subset_on = alldata[\n",
    "        [\"ctcfon.rad21on_\" + realistic_select in x for x in alldata.condition]\n",
    "    ].copy()\n",
    "    subset_off = alldata[\n",
    "        [\"ctcfoff.rad21on_\" + realistic_select in x for x in alldata.condition]\n",
    "    ].copy()\n",
    "    time = pd.DataFrame(\n",
    "        [\n",
    "            1 - subset_on.prediction.mean(),\n",
    "            1 - subset_off.prediction.mean(),\n",
    "            1 - distances_control[distances_control.ctcf == \"on\"].prediction.mean(),\n",
    "            1 - distances_control[distances_control.ctcf == \"off\"].prediction.mean(),\n",
    "            1\n",
    "            - exp_data_filtered[\n",
    "                exp_data_filtered.condition == \"1B1_0min\"\n",
    "            ].prediction.mean(),\n",
    "            1\n",
    "            - exp_data_filtered[\n",
    "                exp_data_filtered.condition == \"1A2_0min\"\n",
    "            ].prediction.mean(),\n",
    "            1\n",
    "            - exp_data_filtered[\n",
    "                exp_data_filtered.condition == \"1B1_120min\"\n",
    "            ].prediction.mean(),\n",
    "            1\n",
    "            - exp_data_filtered[\n",
    "                exp_data_filtered.condition == \"1A2_120min\"\n",
    "            ].prediction.mean(),\n",
    "        ],\n",
    "        columns=[\"time\"],\n",
    "    )\n",
    "\n",
    "    time[\"ctcf\"] = [\"on\", \"off\", \"on\", \"off\", \"on\", \"off\", \"on\", \"off\"]\n",
    "    time[\"type\"] = [\"sim\", \"sim\", \"sim\", \"sim\", \"exp\", \"exp\", \"exp\", \"exp\"]\n",
    "    time[\"cohesin\"] = [\"on\", \"on\", \"off\", \"off\", \"on\", \"on\", \"off\", \"off\"]\n",
    "    time[\"condition\"] = \"cohesin\" + time[\"cohesin\"] + \"_ctcf\" + time[\"ctcf\"]\n",
    "    time[\"index\"] = np.arange(0, len(time))\n",
    "    if realistic_select == realistic_best:\n",
    "        print(f\"{realistic_best} ####\")\n",
    "        print(time)\n",
    "        print(f\"\\n\")\n",
    "        ddsets = [\n",
    "            1 - subset_on.prediction,\n",
    "            1 - subset_off.prediction,\n",
    "            1 - distances_control[distances_control.ctcf == \"on\"].prediction,\n",
    "            1 - distances_control[distances_control.ctcf == \"off\"].prediction,\n",
    "            1 - exp_data_filtered[exp_data_filtered.condition == \"1B1_0min\"].prediction,\n",
    "            1 - exp_data_filtered[exp_data_filtered.condition == \"1A2_0min\"].prediction,\n",
    "            1\n",
    "            - exp_data_filtered[exp_data_filtered.condition == \"1B1_120min\"].prediction,\n",
    "            1\n",
    "            - exp_data_filtered[exp_data_filtered.condition == \"1A2_120min\"].prediction,\n",
    "        ]\n",
    "        stds = []\n",
    "        for dataset in ddsets:\n",
    "            print(len(dataset))\n",
    "            tmp = []\n",
    "            for i in range(10000):\n",
    "                tmp.append(\n",
    "                    dataset.iloc[\n",
    "                        np.random.choice(\n",
    "                            range(len(dataset)), size=int(len(dataset)*0.05), replace=True\n",
    "                        )\n",
    "                    ].mean()\n",
    "                )\n",
    "            stds.append(np.std(tmp))\n",
    "        time[\"std\"] = stds\n",
    "\n",
    "        means = time.pivot(index=\"type\", columns=\"condition\", values=\"time\").T\n",
    "        errors = time.pivot(index=\"type\", columns=\"condition\", values=\"std\").T\n",
    "        fig = means.plot(kind=\"bar\", yerr=errors)\n",
    "        plt.ylabel(\"Fraction of time spent in looped state\")\n",
    "        plt.title(f\"Best case {realistic_best}\")\n",
    "        pdf.savefig(fig.figure, bbox_inches=\"tight\")\n",
    "        time.drop(\"std\", axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "    time_average = pd.concat([time, time_average])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\\n\\n {realistic_list}\")\n",
    "print(\"\\n\\n  AVERAGE\")\n",
    "print(time_average.groupby([\"condition\", \"type\"]).time.mean())\n",
    "print(\"\\n\\n Standard deviation\")\n",
    "print(time_average.groupby([\"condition\", \"type\"]).time.std())\n",
    "ax = sns.barplot(\n",
    "    data=time_average,\n",
    "    hue=\"type\",\n",
    "    x=\"condition\",\n",
    "    y=\"time\",\n",
    "    ci=\"sd\",\n",
    "    capsize=0.1,\n",
    "    estimator=np.mean,\n",
    ")\n",
    "plt.ylim(0, 1)\n",
    "sns.scatterplot(data=time_average, \n",
    "                hue=\"type\",\n",
    "                x=\"condition\",\n",
    "                y=\"time\",\n",
    "                legend=False,\n",
    "                zorder=10,\n",
    "                ax=ax,\n",
    "               )\n",
    "\n",
    "plt.ylabel(\"Fraction of time spent in looped state\")\n",
    "plt.title(f\"average from {realistic_list}\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "pdf.savefig(fig.figure, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of CTCF in best case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_average = pd.DataFrame()\n",
    "for realistic_select in realistic_list:\n",
    "\n",
    "    subset_on = alldata[\n",
    "        [\"ctcfon.rad21on_\" + realistic_select in x for x in alldata.condition]\n",
    "    ].copy()\n",
    "    subset_off = alldata[\n",
    "        [\"ctcfoff.rad21on_\" + realistic_select in x for x in alldata.condition]\n",
    "    ].copy()\n",
    "    time = pd.DataFrame(\n",
    "        [\n",
    "            (1 - subset_on.prediction.mean())\n",
    "            / (1 - subset_off.prediction.mean()),\n",
    "            ft_yesCTCF_yescohesin / ft_noCTCF_yescohesin\n",
    "        ],\n",
    "        columns=[\"time\"],\n",
    "    )\n",
    "\n",
    "    time[\"type\"] = [\"sim HMM\", \"exp\"]\n",
    "    if realistic_select == realistic_best:\n",
    "        print(f\"{realistic_best}\")\n",
    "        print(time)\n",
    "        ax = sns.barplot(data=time, x=\"type\", y=\"time\")\n",
    "        sns.scatterplot(data=time, legend=False, zorder=10, ax=ax)\n",
    "        plt.ylabel(\"Foldchange +ctcf/-ctcf in the presence of cohesin\")\n",
    "        plt.title(f\"Best case {realistic_best}\")\n",
    "        pdf.savefig(ax.figure)\n",
    "    time_average = pd.concat([time, time_average])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "print(f\"\\n\\n{realistic_list}\")\n",
    "print(\"\\n\\n AVERAGE\")\n",
    "print(time_average.groupby([\"type\"]).time.mean())\n",
    "print(\"\\n\\n Standard deviation\")\n",
    "print(time_average.groupby([\"type\"]).time.std())\n",
    "\n",
    "ax = sns.barplot(data=time_average, x=\"type\", y=\"time\", ci=\"sd\", capsize=.1, estimator = np.mean)\n",
    "sns.scatterplot(data=time_average, x=\"type\", y=\"time\", legend=False, zorder=10, ax=ax)\n",
    "plt.ylabel(\"Foldchange +ctcf/-ctcf in the presence of cohesin\")\n",
    "plt.title(f\"average from {realistic_list}\")\n",
    "pdf.savefig(ax.figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contact duration and second passage time of best case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nocohesin = distances_control.copy()\n",
    "nocohesin.condition = nocohesin.uniqueid.map(lambda x: str(x)[:-2])\n",
    "(\n",
    "    durations_nocohesin,\n",
    "    second_passage_times_nocohesin,\n",
    "    frequencies_nocohesin,\n",
    "    fraction_time_nocohesin,\n",
    "    conditions_nocohesin,\n",
    "    data_realistic_nocohesin,\n",
    ") = calculate_duration_second_passage_time(\n",
    "    nocohesin, resolution=30, model=results[realistic_model_best]\n",
    ")\n",
    "\n",
    "(\n",
    "    durations_nocohesin_gt,\n",
    "    second_passage_times_nocohesin_gt,\n",
    "    frequencies_nocohesin_gt,\n",
    "    fraction_time_nocohesin_gt,\n",
    "    conditions_nocohesin_gt,\n",
    "    data_realistic_gt,\n",
    ") = calculate_duration_second_passage_time(\n",
    "    nocohesin, resolution=30, model=results[realistic_model_best], gt=True\n",
    ")\n",
    "\n",
    "cond = realistic_model_best\n",
    "distances_selected = distances[distances.condition == cond].copy()\n",
    "distances_selected.condition = distances_selected.uniqueid.map(lambda x: str(x)[:-2])\n",
    "(\n",
    "    durations,\n",
    "    second_passage_times,\n",
    "    frequencies,\n",
    "    fraction_time,\n",
    "    conditions,\n",
    "    data_realistic,\n",
    ") = calculate_duration_second_passage_time(\n",
    "    distances_selected, resolution=30, model=results[realistic_model_best]\n",
    ")\n",
    "\n",
    "(\n",
    "    durations_gt,\n",
    "    second_passage_times_gt,\n",
    "    frequencies_gt,\n",
    "    fraction_time_gt,\n",
    "    conditions_gt,\n",
    "    data_realistic_gt,\n",
    ") = calculate_duration_second_passage_time(\n",
    "    distances_selected, resolution=30, model=results[realistic_model_best], gt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contact duration\n",
    "durations[\"ctcf\"] = durations.condition.str.split(\".\", expand=True)[0]\n",
    "durations[\"ctcf\"] = durations[\"ctcf\"] + \"_cohesinon\"\n",
    "durations_gt[\"ctcf\"] = durations_gt.condition.str.split(\".\", expand=True)[0]\n",
    "durations_gt[\"ctcf\"] = durations_gt[\"ctcf\"] + \"_cohesinon_gt\"\n",
    "durations_nocohesin[\"ctcf\"] = durations_nocohesin.condition.str.split(\".\", expand=True)[\n",
    "    0\n",
    "]\n",
    "durations_nocohesin[\"ctcf\"] = durations_nocohesin[\"ctcf\"] + \"_nocohesin\"\n",
    "durations_nocohesin_gt[\"ctcf\"] = durations_nocohesin_gt.condition.str.split(\n",
    "    \".\", expand=True\n",
    ")[0]\n",
    "durations_nocohesin_gt[\"ctcf\"] = durations_nocohesin_gt[\"ctcf\"] + \"_nocohesin_gt\"\n",
    "exp_durations[\"ctcf\"] = exp_durations[\"condition\"]\n",
    "\n",
    "durations = pd.concat(\n",
    "    [\n",
    "        durations,\n",
    "        durations_gt,\n",
    "        exp_durations,\n",
    "        durations_nocohesin,\n",
    "        durations_nocohesin_gt,\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"{realistic_best}\")\n",
    "print(\"\\n\\n AVERAGE\")\n",
    "print(durations.groupby([\"ctcf\"]).contact_duration.mean())\n",
    "print(\"\\n\\n Standard deviation\")\n",
    "print(durations.groupby([\"ctcf\"]).contact_duration.std())\n",
    "\n",
    "fig = plt.figure()\n",
    "box_plot = sns.barplot(data=durations, x=\"ctcf\", y=\"contact_duration\")\n",
    "\n",
    "ax = box_plot.axes\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "# plt.yscale('log')\n",
    "plt.xlabel(\"sample\")\n",
    "plt.ylabel(\"Contact duration (1/koff)\")\n",
    "plt.title(realistic_best)\n",
    "plt.show()\n",
    "pdf.savefig(box_plot.figure, bbox_inches=\"tight\")\n",
    "\n",
    "second_passage_times[\"ctcf\"] = second_passage_times.condition.str.split(\n",
    "    \".\", expand=True\n",
    ")[0]\n",
    "second_passage_times[\"ctcf\"]  = second_passage_times[\"ctcf\"]  + \"_cohesinon\"\n",
    "second_passage_times_gt[\"ctcf\"] = second_passage_times_gt.condition.str.split(\n",
    "    \".\", expand=True\n",
    ")[0]\n",
    "second_passage_times_gt[\"ctcf\"] = second_passage_times_gt[\"ctcf\"] + \"_cohesinon_gt\"\n",
    "second_passage_times_nocohesin[\n",
    "    \"ctcf\"\n",
    "] = second_passage_times_nocohesin.condition.str.split(\".\", expand=True)[0]\n",
    "second_passage_times_nocohesin[\"ctcf\"] = (\n",
    "    second_passage_times_nocohesin[\"ctcf\"] + \"_nocohesin\"\n",
    ")\n",
    "second_passage_times_nocohesin_gt[\n",
    "    \"ctcf\"\n",
    "] = second_passage_times_nocohesin_gt.condition.str.split(\".\", expand=True)[0]\n",
    "second_passage_times_nocohesin_gt[\"ctcf\"] = (\n",
    "    second_passage_times_nocohesin_gt[\"ctcf\"] + \"_nocohesin_gt\"\n",
    ")\n",
    "exp_second_passage_times[\"ctcf\"] = exp_second_passage_times[\"condition\"]\n",
    "\n",
    "second_passage_times = pd.concat(\n",
    "    [\n",
    "        second_passage_times,\n",
    "        second_passage_times_gt,\n",
    "        exp_second_passage_times,\n",
    "        second_passage_times_nocohesin_gt,\n",
    "        second_passage_times_nocohesin,\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"\\n\\n  {realistic_best}\")\n",
    "print(\"\\n\\n  AVERAGE\")\n",
    "print(second_passage_times.groupby([\"ctcf\"]).second_passage_time.mean())\n",
    "print(\"\\n\\n  Standard deviation\")\n",
    "print(second_passage_times.groupby([\"ctcf\"]).second_passage_time.std())\n",
    "\n",
    "fig = plt.figure()\n",
    "box_plot = sns.barplot(\n",
    "    data=second_passage_times,\n",
    "    x=\"ctcf\",\n",
    "    y=\"second_passage_time\",\n",
    "    estimator=lambda x: 1 / np.mean(x),\n",
    ")\n",
    "\n",
    "ax = box_plot.axes\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"sample\")\n",
    "plt.ylabel(\"1/second_passage_time (kon)\")\n",
    "plt.title(realistic_best)\n",
    "plt.show()\n",
    "pdf.savefig(box_plot.figure, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_conditions = durations.ctcf.unique()\n",
    "for i in range(len(list_conditions)):\n",
    "    for j in range(i + 1, len(list_conditions)):\n",
    "        test = scipy.stats.ttest_ind(\n",
    "            durations.contact_duration[durations.ctcf == list_conditions[i]].values,\n",
    "            durations.contact_duration[durations.ctcf == list_conditions[j]].values,\n",
    "        )\n",
    "        print(f\"{list_conditions[i]} vs {list_conditions[j]} p-value pfrom two sided t.test {test.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_conditions = second_passage_times.ctcf.unique()\n",
    "for i in range(len(list_conditions)):\n",
    "    for j in range(i + 1, len(list_conditions)):\n",
    "        test = scipy.stats.ttest_ind(\n",
    "            second_passage_times.second_passage_time[second_passage_times.ctcf == list_conditions[i]].values,\n",
    "            second_passage_times.second_passage_time[second_passage_times.ctcf == list_conditions[j]].values,\n",
    "        )\n",
    "        print(f\"{list_conditions[i]} vs {list_conditions[j]} p-value pfrom two sided t.test {test.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average change in second passage time\n",
    "sptimes = second_passage_times.groupby(\"ctcf\").mean()[\"second_passage_time\"]\n",
    "changes = [\n",
    "    sptimes.loc[\"1A2_0min\"] / sptimes.loc[\"1B1_0min\"],\n",
    "    sptimes.loc[\"ctcfoff_cohesinon\"] / sptimes.loc[\"ctcfon_cohesinon\"],\n",
    "    sptimes.loc[\"1A2_120min\"] / sptimes.loc[\"1A2_0min\"],\n",
    "    sptimes.loc[\"ctcfoff_nocohesin\"] / sptimes.loc[\"ctcfoff_cohesinon\"],\n",
    "    sptimes.loc[\"1A2_120min\"] / sptimes.loc[\"1B1_0min\"],\n",
    "    sptimes.loc[\"ctcfoff_nocohesin\"] / sptimes.loc[\"ctcfon_cohesinon\"],\n",
    "];\n",
    "conditions = [\n",
    "    \"+cohesin +/-CTCF\",\n",
    "    \"+cohesin +/-ctcf sim\",\n",
    "    \"-CTCF +/-cohesin\",\n",
    "    \"-CTCF +/-cohesin sim\",\n",
    "    \"-CTCF-cohesin/+CTCF+cohesin\",\n",
    "    \"-CTCF-cohesin/+CTCF+cohesin sim\",\n",
    "];\n",
    "\n",
    "\n",
    "for x,y in zip(changes, conditions):\n",
    "    print(x,y)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "df = pd.DataFrame(changes, columns=[\"Change in 1/second_passage_time\"])\n",
    "df[\"condition\"] = conditions\n",
    "box_plot = sns.barplot(data=df, x=\"condition\", y=\"Change in 1/second_passage_time\", ax = ax[0])\n",
    "ax1 = box_plot.axes\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "ax1.set_title(f\"{realistic_best} linear scale\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(np.log10(changes), columns=[\"Change in 1/second_passage_time\"])\n",
    "df[\"condition\"] = conditions\n",
    "box_plot = sns.barplot(data=df, x=\"condition\", y=\"Change in 1/second_passage_time\", ax = ax[1])\n",
    "ax1 = box_plot.axes\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "ax1.set_title(f\"{realistic_best} log scale\")\n",
    "pdf.savefig(box_plot.figure, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average change in durations\n",
    "cdtimes = durations.groupby(\"ctcf\").mean()[\"contact_duration\"]\n",
    "changes = [\n",
    "     cdtimes.loc[\"1B1_0min\"] / cdtimes.loc[\"1A2_0min\"],\n",
    "    cdtimes.loc[\"ctcfon_cohesinon\"] / cdtimes.loc[\"ctcfoff_cohesinon\"],\n",
    "    cdtimes.loc[\"1A2_0min\"] / cdtimes.loc[\"1A2_120min\"],\n",
    "    cdtimes.loc[\"ctcfoff_cohesinon\"] / cdtimes.loc[\"ctcfoff_nocohesin\"],\n",
    "    cdtimes.loc[\"1B1_0min\"] / cdtimes.loc[\"1A2_120min\"],\n",
    "    cdtimes.loc[\"ctcfon_cohesinon\"] / cdtimes.loc[\"ctcfoff_nocohesin\"],\n",
    "];\n",
    "conditions = [\n",
    "    \"+cohesin +/-CTCF\",\n",
    "    \"+cohesin +/-ctcf sim\",\n",
    "    \"-CTCF +/-cohesin\",\n",
    "    \"-CTCF +/-cohesin sim\",\n",
    "    \"-CTCF-cohesin/+CTCF+cohesin\",\n",
    "    \"-CTCF-cohesin/+CTCF+cohesin sim\",\n",
    "];\n",
    "\n",
    "for x,y in zip(changes, conditions):\n",
    "    print(x,y)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "df = pd.DataFrame(changes, columns=[\"Change in contact duration\"])\n",
    "df[\"condition\"] = conditions\n",
    "box_plot = sns.barplot(data=df, x=\"condition\", y=\"Change in contact duration\", ax = ax[0])\n",
    "ax1 = box_plot.axes\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "ax1.set_title(f\"{realistic_best} linear scale\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(np.log10(changes), columns=[\"Change in contact duration\"])\n",
    "df[\"condition\"] = conditions\n",
    "box_plot = sns.barplot(data=df, x=\"condition\", y=\"Change in contact duration\", ax = ax[1])\n",
    "ax1 = box_plot.axes\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=90)\n",
    "ax1.set_title(f\"{realistic_best} log scale\")\n",
    "pdf.savefig(box_plot.figure, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# simulation\n",
    "durations_all = pd.DataFrame()\n",
    "durations_all_gt = pd.DataFrame()\n",
    "second_passage_times_all = pd.DataFrame()\n",
    "second_passage_times_all_gt = pd.DataFrame()\n",
    "fraction_of_time_all = pd.DataFrame()\n",
    "fraction_of_time_all_gt = pd.DataFrame()\n",
    "\n",
    "for cond in realistic_model_list:\n",
    "    distances_selected = (\n",
    "        distances[distances.condition == cond].iloc[::subsample_every].copy()\n",
    "    )\n",
    "\n",
    "    naked = distances_control.copy()\n",
    "\n",
    "    distances_selected.condition = distances_selected.uniqueid\n",
    "    (\n",
    "        durations,\n",
    "        second_passage_times,\n",
    "        frequencies,\n",
    "        fraction_time,\n",
    "        conditions,\n",
    "        data_realistic,\n",
    "    ) = calculate_duration_second_passage_time(\n",
    "        distances_selected, resolution=30, model=results[cond]\n",
    "    )\n",
    "\n",
    "    durations_all = pd.concat([durations_all, durations])\n",
    "    second_passage_times_all = pd.concat(\n",
    "        [second_passage_times, second_passage_times_all]\n",
    "    )\n",
    "\n",
    "    (\n",
    "        durations_gt,\n",
    "        second_passage_times_gt,\n",
    "        frequencies_gt,\n",
    "        fraction_time_gt,\n",
    "        conditions_gt,\n",
    "        data_realistic_gt,\n",
    "    ) = calculate_duration_second_passage_time(\n",
    "        distances_selected, resolution=30, model=results[cond], gt=True\n",
    "    )\n",
    "    durations_all_gt = pd.concat([durations_all_gt, durations_gt])\n",
    "    second_passage_times_all_gt = pd.concat(\n",
    "        [second_passage_times_all_gt, second_passage_times_gt]\n",
    "    )\n",
    "\n",
    "# Contact duration\n",
    "durations_all[\"ctcf\"] = durations_all.condition.str.split(\".\", expand=True)[0]\n",
    "durations_all[\"ctcf\"] = durations_all[\"ctcf\"] + \"_cohesinon\"\n",
    "durations_all_gt[\"ctcf\"] = durations_all_gt.condition.str.split(\".\", expand=True)[0]\n",
    "durations_all_gt[\"ctcf\"] = durations_all_gt[\"ctcf\"] + \"_cohesinon_gt\"\n",
    "exp_durations[\"ctcf\"] = exp_durations[\"condition\"]\n",
    "\n",
    "durations_all = pd.concat(\n",
    "    [\n",
    "        durations_all,\n",
    "        durations_all_gt,\n",
    "        exp_durations,\n",
    "        durations_nocohesin,\n",
    "        durations_nocohesin_gt,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"\\n\\n{realistic_model_list}\")\n",
    "print(\"\\n\\n AVERAGE\")\n",
    "print(durations_all.groupby([\"ctcf\"]).contact_duration.mean())\n",
    "print(\"\\n\\n Standard deviation\")\n",
    "print(durations_all.groupby([\"ctcf\"]).contact_duration.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_cd = durations_all.copy()\n",
    "tmp_df_cd.induction_time = tmp_df_cd.condition.map(lambda x: str(x)[:-2])+tmp_df_cd.ctcf\n",
    "tmp_df_cd['cont_dur_aver'] = tmp_df_cd['contact_duration'].groupby(tmp_df_cd['induction_time']).transform('mean')\n",
    "tmp_df_cd['cont_dur_std'] = tmp_df_cd['cont_dur_aver'].groupby(tmp_df_cd['ctcf']).transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot = sns.barplot(data=tmp_df_cd, x=\"ctcf\", y=\"cont_dur_aver\", ci='sd')\n",
    "ax = box_plot.axes\n",
    "sns.scatterplot(\n",
    "    data=tmp_df_cd,\n",
    "    x=\"ctcf\",\n",
    "    y=\"cont_dur_aver\",\n",
    "    #join=False,\n",
    "    ax=ax,\n",
    "    legend=False,\n",
    "    zorder=10)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"sample\")\n",
    "plt.ylabel(\"Contact duration (1/koff)\")\n",
    "plt.title(list(realistic_list))\n",
    "pdf.savefig(box_plot.figure, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_passage_times_all[\"ctcf\"] = second_passage_times_all.condition.str.split(\n",
    "    \".\", expand=True\n",
    ")[0]\n",
    "second_passage_times_all[\"ctcf\"] = second_passage_times_all[\"ctcf\"] + \"_cohesinon\"\n",
    "second_passage_times_all_gt[\"ctcf\"] = second_passage_times_all_gt.condition.str.split(\n",
    "    \".\", expand=True\n",
    ")[0]\n",
    "second_passage_times_all_gt[\"ctcf\"] = (\n",
    "    second_passage_times_all_gt[\"ctcf\"] + \"_cohesinon_gt\"\n",
    ")\n",
    "exp_second_passage_times[\"ctcf\"] = exp_second_passage_times[\"condition\"]\n",
    "\n",
    "second_passage_times = pd.concat(\n",
    "    [\n",
    "        second_passage_times_all,\n",
    "        second_passage_times_all_gt,\n",
    "        exp_second_passage_times,\n",
    "        second_passage_times_nocohesin_gt,\n",
    "        second_passage_times_nocohesin,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df_spt = second_passage_times.copy()\n",
    "tmp_df_spt.induction_time = tmp_df_spt.condition.map(lambda x: str(x)[:-2])+tmp_df_spt.ctcf\n",
    "tmp_df_spt['spt_aver'] = 1/tmp_df_spt['second_passage_time'].groupby(tmp_df_spt['induction_time']).transform('mean')\n",
    "tmp_df_spt['spt_std'] = tmp_df_spt['spt_aver'].groupby(tmp_df_spt['ctcf']).transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot = sns.barplot(data=tmp_df_spt, x=\"ctcf\", y=\"spt_aver\", ci='sd')\n",
    "\n",
    "ax = box_plot.axes\n",
    "sns.scatterplot(\n",
    "    data=tmp_df_spt,\n",
    "    x=\"ctcf\",\n",
    "    y=\"spt_aver\",\n",
    "    ax=ax,\n",
    "    legend=False,\n",
    "    zorder=10)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "plt.xlabel(\"sample\")\n",
    "plt.ylabel(\"1/second_passage_time (kon)\")\n",
    "plt.title(list(realistic_list))\n",
    "pdf.savefig(box_plot.figure, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distance distribution of best  case and comparison with experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_subset = alldata[[\"rad21on_\" + realistic_best in x for x in alldata.condition]].copy()\n",
    "best_subset_on = best_subset[best_subset.ctcf==\"on\"].copy()\n",
    "best_subset_off = best_subset[best_subset.ctcf==\"off\"].copy()\n",
    "dist = exp_data_filtered[(exp_data_filtered.condition == \"1B1_0min\")].copy()\n",
    "\n",
    "distance = dist.distance.values.reshape(-1, 1)\n",
    "states = (exp_model.predict(distance))\n",
    "dist['states'] = states\n",
    "dist[\"states_numeric\"] = dist.states.values\n",
    "dist.states.replace(0, \"looped\", inplace=True)\n",
    "dist.states.replace(1, \"unlooped\", inplace=True)\n",
    "\n",
    "hists = []\n",
    "hist = plt.hist(best_subset_on.distance[best_subset_on.prediction==0], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(best_subset_on.distance[best_subset_on.prediction==1], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(best_subset_on.distance, density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(dist.distance[dist.states == \"looped\"], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "for hist in hists:\n",
    "    plt.plot( hist[1][:-1], hist[0]/np.sum(hist[0]))\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(\"Distance (nm)\")\n",
    "plt.ylabel(\"Fraction of distances\")\n",
    "plt.legend([\"Sim looped\", \"Sim noloop\", \"all_sim\", \"exp 1B1_0min looped\"])\n",
    "plt.title(f\"best case {realistic_best}\")\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = []\n",
    "hist = plt.hist(best_subset_on.distance[best_subset_on.prediction==0], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(dist.distance[dist.states==\"looped\"], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "for hist in hists:\n",
    "    plt.plot( hist[1][:-1], hist[0]/np.sum(hist[0]))\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(\"Distance (nm)\")\n",
    "plt.ylabel(\"Fraction of distances\")\n",
    "plt.legend([\"Sim looped\", \"exp looped\"])\n",
    "plt.title(realistic_best)\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = realistic_list#dist_together.sort_values('dist_gaussian_means').head(5).realistic\n",
    "\n",
    "hists = []\n",
    "for cond in conditions:\n",
    "    subset_on = alldata[[\"rad21on_\" + cond in x for x in alldata.condition]].copy()\n",
    "    hist = plt.hist(subset_on.distance[subset_on.prediction==0], alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "    hists.append(hist)\n",
    "\n",
    "\n",
    "hist=plt.hist(dist.distance[dist.states==\"looped\"], alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "conditions = np.append(conditions , \"exp looped\")\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "for hist in hists[:-1]:\n",
    "    plt.plot( hist[1][:-1], hist[0]/np.sum(hist[0]))\n",
    "    \n",
    "plt.plot(hists[-1][1][:-1], hists[-1][0]/np.sum(hists[-1][0]), color='black', linewidth=6)\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(\"Distance (nm)\")\n",
    "plt.ylabel(\"Fraction of distances\")\n",
    "plt.legend(conditions)\n",
    "plt.title(\"looped state\")\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = []\n",
    "hist=plt.hist(best_subset_on.distance, density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(best_subset_off.distance, density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(distances_control.distance, density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(exp.distance[exp.condition == \"1B1_0min\"], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(exp.distance[exp.condition == \"1B1_120min\"], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(exp.distance[exp.condition == \"1A2_0min\"], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "hist=plt.hist(exp.distance[exp.condition == \"1A2_120min\"], density=True, alpha=0.3, bins=np.arange(0,5,0.01))\n",
    "hists.append(hist)\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure()\n",
    "for hist in hists:\n",
    "    plt.plot( hist[1][:-1], hist[0]/np.sum(hist[0]))\n",
    "plt.xlim(0,1)\n",
    "plt.xlabel(\"Distance (nm)\")\n",
    "plt.ylabel(\"Fraction of distances\")\n",
    "plt.legend([\"CTCF on\", \"CTCF off\", \"naked\", \"1B1_0min\", \"1B1_120min\", \"1A2_0min\", \"1A2_120min\"])\n",
    "plt.title(realistic_best)\n",
    "pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_conds = [\"1B1_0min\", \"1B1_120min\", \"1A2_0min\", \"1A2_120min\"]\n",
    "print(\"condition\", '\\t', 'mean', '\\t','\\t', '\\t','variance (square of std)')\n",
    "print(\"-------------------------------------------------\")\n",
    "for cond in lst_conds:\n",
    "    print(cond,'\\t',\n",
    "          np.mean(exp.distance[exp.condition == cond]), '\\t',\n",
    "          np.std(exp.distance[exp.condition == cond])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example tracks with GT and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +/- ctcf tracks\n",
    "for ctcf, sub in best_subset.groupby(\"ctcf\"):\n",
    "    for limitstart in range(250,12000, 250):\n",
    "        limit = limitstart + 250\n",
    "        fig = plt.figure()\n",
    "        plt.plot(sub.frame.values[limitstart:limit]*30, sub.distance.values[limitstart:limit])\n",
    "        plt.plot(sub.frame.values[limitstart:limit]*30, sub.bond.values[limitstart:limit], alpha=0.8)\n",
    "        plt.plot(sub.frame.values[limitstart:limit]*30, sub.prediction.values[limitstart:limit], alpha=0.5)\n",
    "        plt.legend(['track', 'gt', 'pred'])\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        plt.ylabel(\"Distance (um)\")\n",
    "        plt.title(\"ctcf_\" + ctcf + \"_\" + realistic_best)\n",
    "        plt.show()\n",
    "        plt.ylim(-0.2,1.2)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naked polymer\n",
    "\n",
    "traj = distances_control.distance.values.reshape(-1, 1)\n",
    "m = results[realistic_model_best]\n",
    "distances_control[\"prediction\"] = m.predict(traj)\n",
    "\n",
    "sub = distances_control.copy()\n",
    "for ctcf, sub in distances_control.groupby(\"ctcf\"):\n",
    "    for limitstart in range(250,12000, 250):\n",
    "        limit = limitstart + 250\n",
    "        fig = plt.figure()\n",
    "\n",
    "        plt.plot(sub.frame.values[limitstart:limit]*30, sub.distance.values[limitstart:limit])\n",
    "        plt.plot(sub.frame.values[limitstart:limit]*30, sub.bond.values[limitstart:limit], alpha=0.8)\n",
    "        plt.plot(sub.frame.values[limitstart:limit]*30, sub.prediction.values[limitstart:limit], alpha=0.5)\n",
    "        plt.legend(['track', 'gt', 'pred'])\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        plt.ylabel(\"Distance (um)\")\n",
    "        plt.title(\"-cohesin \" + realistic_best + \"ctcf\" + ctcf)\n",
    "        plt.ylim(-0.2,1.2)\n",
    "        plt.show()\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for limitstart in range(250,12000, 250):\n",
    "    limit = limitstart + 250\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.plot(distances.frame.values[limitstart:limit]*30, distances.distance.values[limitstart:limit], alpha=0.8)\n",
    "    plt.plot(distances.frame.values[limitstart:limit]*30, distances_nonoise.distance.values[limitstart:limit], alpha=0.8)\n",
    "    plt.legend(['+noise', '-noise'])\n",
    "    plt.xlabel(\"time (s)\")\n",
    "    plt.ylabel(\"Distance (um)\")\n",
    "    plt.ylim(-0.2,1.2)\n",
    "    plt.show()\n",
    "    pdf.savefig(fig)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
